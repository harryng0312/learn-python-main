{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b80757289ac441a192d4ddb74dd5a050":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9073e1c3c99d41dda10c1dfb5044b920","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_87e2ced98b984509bf56d405ea89e371","IPY_MODEL_fb43dee2d8ca4bcb89af427f3e4aced8"]}},"9073e1c3c99d41dda10c1dfb5044b920":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"87e2ced98b984509bf56d405ea89e371":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bc276a8c7c8e4907a1729e8a0ef529b9","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":557,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":557,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_02763daebcf34dbf910ed8fce9c90bd2"}},"fb43dee2d8ca4bcb89af427f3e4aced8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2b763c4efe624f30badb78efd74dd9fc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 557/557 [00:00&lt;00:00, 913B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9bf9023ca07640698d7b80c0dde6981b"}},"bc276a8c7c8e4907a1729e8a0ef529b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"02763daebcf34dbf910ed8fce9c90bd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2b763c4efe624f30badb78efd74dd9fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9bf9023ca07640698d7b80c0dde6981b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"598453649f214fc6bc84d33824fd29e7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1dc7bb6340d746bfa06eea7f08f8f590","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_167ce4278b0647c19f24346ce1f6a804","IPY_MODEL_26fa14b6d2914b1c98dd8e88b3288b41"]}},"1dc7bb6340d746bfa06eea7f08f8f590":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"167ce4278b0647c19f24346ce1f6a804":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8988ec43f415476d8d30a39e6fbec6b8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":542923308,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":542923308,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c1a0e28caa04466b86477c30c73e380d"}},"26fa14b6d2914b1c98dd8e88b3288b41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_33e0e55f1639454b9f053479a347bf73","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 543M/543M [00:42&lt;00:00, 12.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8313780860da438d921be2a3e0c8cb0c"}},"8988ec43f415476d8d30a39e6fbec6b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c1a0e28caa04466b86477c30c73e380d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"33e0e55f1639454b9f053479a347bf73":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8313780860da438d921be2a3e0c8cb0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bd15c33cba3a4c5b80ad7d72b0a83569":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_48ab4820bb99402a88216d99e2197774","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cbfa7e1d420b49afab449cdf3f474edb","IPY_MODEL_05f48704e71e4270b67a3c39a5b60d90"]}},"48ab4820bb99402a88216d99e2197774":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cbfa7e1d420b49afab449cdf3f474edb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_60a4c14d115d403e821fb185838c6a46","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":895321,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":895321,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b82155807589494da0c6812d85bdb1f8"}},"05f48704e71e4270b67a3c39a5b60d90":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e29698db0b524ac48258dddb92dad1fc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 895k/895k [00:03&lt;00:00, 265kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_91672bd7667b4253b4d4fc5bafaf4b54"}},"60a4c14d115d403e821fb185838c6a46":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b82155807589494da0c6812d85bdb1f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e29698db0b524ac48258dddb92dad1fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"91672bd7667b4253b4d4fc5bafaf4b54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fc89383e67ae457c9f36136394682019":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_23a7b19a06b646a48c35af80dfed09e3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_39856d05c62046538dcdf6e0aa012e54","IPY_MODEL_8ecbae8e162a433994eaefae85ed5054"]}},"23a7b19a06b646a48c35af80dfed09e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"39856d05c62046538dcdf6e0aa012e54":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d19f03a9fd6f490194b23921a730fd2e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1135173,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1135173,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0e17824f89cb4605b35114e3f9dbf598"}},"8ecbae8e162a433994eaefae85ed5054":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_19d85a09096a40c385368bd132f45032","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.14M/1.14M [00:01&lt;00:00, 973kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_19a5541e62564a3daf134ec1aa6819d1"}},"d19f03a9fd6f490194b23921a730fd2e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0e17824f89cb4605b35114e3f9dbf598":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19d85a09096a40c385368bd132f45032":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"19a5541e62564a3daf134ec1aa6819d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"28aa0d7e7a964bb0bd1b6ace410ef00d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e74161468185435a9338b218eb4aed72","IPY_MODEL_c9e533ddcac747bfafc872c46a104b61"],"layout":"IPY_MODEL_62d02ae7fa8349d4895b192bce2d6706"}},"e74161468185435a9338b218eb4aed72":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_b214f352f8be47faa7e52df25ea39270","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_06a15da863d749c59927e00e4bc57c40","value":665}},"c9e533ddcac747bfafc872c46a104b61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbbb250469d2403eb78ea45ed5d62657","placeholder":"​","style":"IPY_MODEL_db4e831ac34341f9a417b3ce94fbc177","value":" 665/665 [00:15&lt;00:00, 42.9B/s]"}},"62d02ae7fa8349d4895b192bce2d6706":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b214f352f8be47faa7e52df25ea39270":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06a15da863d749c59927e00e4bc57c40":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"fbbb250469d2403eb78ea45ed5d62657":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db4e831ac34341f9a417b3ce94fbc177":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86a2c7e098fb40a58d83f97fc4fc39f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db9467ece2ae427cb93793b353d5903f","IPY_MODEL_52ff69fb0ec34c6bad0be29956351f0d"],"layout":"IPY_MODEL_ad0667c9af34402f8733279ff4c73b9f"}},"db9467ece2ae427cb93793b353d5903f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_2f04c89f3a5d4a8ea42ac37a9b509e71","max":548118077,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68e2fb4f69a648359362872fd61831c6","value":548118077}},"52ff69fb0ec34c6bad0be29956351f0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d424fc2bc4f14a3c843e620b39b10c8b","placeholder":"​","style":"IPY_MODEL_0379aa738c79419d9a6a25309a12c70d","value":" 548M/548M [00:09&lt;00:00, 60.9MB/s]"}},"ad0667c9af34402f8733279ff4c73b9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f04c89f3a5d4a8ea42ac37a9b509e71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68e2fb4f69a648359362872fd61831c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"d424fc2bc4f14a3c843e620b39b10c8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0379aa738c79419d9a6a25309a12c70d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"uBvpZ0oVhNTW"},"source":["# **What are we going to do:**\n","\n","1. Craw data poemtry from internet and saved\n","2. Preprocessing data, and write **DataLoader** ( return tokenizer of poemtry)\n","3. Initialize Trainer with TrainingArguments and GPT-2 model\n","4. Train and save the model\n","5. test the model"]},{"cell_type":"markdown","metadata":{"id":"F2PJAkeueYx3"},"source":[" *CHECK CUDA, INSTALL LIBRARY NECCESSARY*"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q1EoxpRnFnPp","executionInfo":{"status":"ok","timestamp":1607795117665,"user_tz":-420,"elapsed":256630,"user":{"displayName":"truc tran trung","photoUrl":"","userId":"16854322956484545035"}},"outputId":"1552166e-5a6c-487e-b5c2-6389f99ff3af"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bFhrOOgBsjeq","executionInfo":{"status":"ok","timestamp":1607795117678,"user_tz":-420,"elapsed":1812,"user":{"displayName":"truc tran trung","photoUrl":"","userId":"16854322956484545035"}},"outputId":"ac8b3859-ec7e-446b-934b-40d35a2c1ab7"},"source":["import os\n","path = '/content/drive/MyDrive/BERT'\n","os.chdir(path)\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["68cleanregex.txt\n","68cleanvl_test.txt\n","cached_lm_PhobertTokenizer_254_68cleanregex.txt\n","cached_lm_PhobertTokenizer_254_68cleanregex.txt.lock\n","cached_lm_PhobertTokenizer_254_68cleanvl_test.txt\n","cached_lm_PhobertTokenizer_254_68cleanvl_test.txt.lock\n","gpt2-poem\n","sample.txt\n","save_modelGPT2\n","Untitled0.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VqdWQXd024qP","executionInfo":{"elapsed":22373,"status":"ok","timestamp":1607600578218,"user":{"displayName":"truc tran trung","photoUrl":"","userId":"16854322956484545035"},"user_tz":-420},"outputId":"fccf95b0-2e3f-4771-95b1-0c8ec2f14464"},"source":["import torch\n","torch.__version__\n","torch.cuda.is_available()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NM9OuuTpA9a1","executionInfo":{"status":"ok","timestamp":1607795156436,"user_tz":-420,"elapsed":31775,"user":{"displayName":"truc tran trung","photoUrl":"","userId":"16854322956484545035"}},"outputId":"4fff0a63-7c32-46b4-89d2-58b57bf5b8fb"},"source":["!pip install transformers\n","!pip3 install fairseq\n","!pip3 install fastbpe\n","!pip3 install vncorenlp"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 6.0MB/s \n","\u001b[?25hCollecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 31.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 28.4MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=449d5aed50317afb94536a58cfcf6541820b2939143657ce70537ea6f89eb379\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n","Collecting fairseq\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/da/7c7032988dade3b21ccfd5b226e50b382abfd3459129d67240bb004506ae/fairseq-0.10.1-cp36-cp36m-manylinux1_x86_64.whl (1.7MB)\n","\u001b[K     |████████████████████████████████| 1.7MB 5.8MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.8)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.7.0+cu101)\n","Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.4)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.21)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.5)\n","Collecting hydra-core\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/1f/7f502b9e37596164111655861370b08626f46f9e4524433c354f472765d4/hydra_core-1.0.4-py3-none-any.whl (122kB)\n","\u001b[K     |████████████████████████████████| 122kB 35.6MB/s \n","\u001b[?25hCollecting sacrebleu>=1.4.12\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n","\u001b[K     |████████████████████████████████| 71kB 9.5MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.41.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (3.7.4.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (0.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n","Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from hydra-core->fairseq) (3.3.0)\n","Collecting omegaconf>=2.0.5\n","  Downloading https://files.pythonhosted.org/packages/e5/f6/043b6d255dd6fbf2025110cea35b87f4c5100a181681d8eab496269f0d5b/omegaconf-2.0.5-py3-none-any.whl\n","Collecting antlr4-python3-runtime==4.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n","\u001b[K     |████████████████████████████████| 112kB 24.0MB/s \n","\u001b[?25hCollecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core->fairseq) (3.4.0)\n","Collecting PyYAML>=5.1.*\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n","\u001b[K     |████████████████████████████████| 276kB 41.9MB/s \n","\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime, PyYAML\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp36-none-any.whl size=141231 sha256=ece4e6914d9bacc41931e4520c919086466cb3ba9fea34816f57d40bf21e0529\n","  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n","  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44620 sha256=7e7344fee39afc4659e14f1fa644aa877cfc434ccad9965ad2a46b36b0eb93dd\n","  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n","Successfully built antlr4-python3-runtime PyYAML\n","Installing collected packages: PyYAML, omegaconf, antlr4-python3-runtime, hydra-core, portalocker, sacrebleu, fairseq\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-5.3.1 antlr4-python3-runtime-4.8 fairseq-0.10.1 hydra-core-1.0.4 omegaconf-2.0.5 portalocker-2.0.0 sacrebleu-1.4.14\n","Collecting fastbpe\n","  Downloading https://files.pythonhosted.org/packages/e1/37/f97181428a5d151501b90b2cebedf97c81b034ace753606a3cda5ad4e6e2/fastBPE-0.1.0.tar.gz\n","Building wheels for collected packages: fastbpe\n","  Building wheel for fastbpe (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fastbpe: filename=fastBPE-0.1.0-cp36-cp36m-linux_x86_64.whl size=481506 sha256=7ff1deae9d2781706fe209120cdd88a0edd6141d06b3e048789be2d528bb3aba\n","  Stored in directory: /root/.cache/pip/wheels/f3/0c/9c/fc62058b4d473a5602bcd3d3edfece796f123875379ea82d79\n","Successfully built fastbpe\n","Installing collected packages: fastbpe\n","Successfully installed fastbpe-0.1.0\n","Collecting vncorenlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/c2/96a60cf75421ecc740829fa920c617b3dd7fa6791e17554e7c6f3e7d7fca/vncorenlp-1.0.3.tar.gz (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.7MB 6.0MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vncorenlp) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2020.12.5)\n","Building wheels for collected packages: vncorenlp\n","  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-cp36-none-any.whl size=2645934 sha256=b0f588aa09c356fb1f5765c12f9bcb5bbbbd03d1f6241699708f820c66803ed0\n","  Stored in directory: /root/.cache/pip/wheels/09/54/8b/043667de6091d06a381d7745f44174504a9a4a56ecc9380c54\n","Successfully built vncorenlp\n","Installing collected packages: vncorenlp\n","Successfully installed vncorenlp-1.0.3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"F7RJHT-fifSt"},"source":["# **Step1 : Craw data in internet and save 2 file train, test**"]},{"cell_type":"code","metadata":{"id":"6iLDmQTFb-C5"},"source":["train_path = '/content/drive/MyDrive/BERT/68cleanregex.txt'\n","test_path = '/content/drive/MyDrive/BERT/68cleanvl_test.txt'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qrYeYbls3y_O"},"source":["# 2 direct load Pretrain Model PhoBERT :\n","( load pretrain model PhoBERT to preprocessing data => write dataLoader)\n","\n","1.   Use fairseq\n","2.   Use transformers\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VRGPZj02fs7u"},"source":["# Case 1 : Load pretrainModel PhoBERT use fairseq"]},{"cell_type":"code","metadata":{"id":"OQN_nor-Fah_"},"source":["# #--------------Load the model in fairseq-----------------#\n","# from fairseq.models.roberta import RobertaModel\n","# phoBERT = RobertaModel.from_pretrained('PhoBERT_base_fairseq', checkpoint_file='model.pt')\n","\n","# #-------------------BPE encoding -----------------------#\n","# from fairseq.data.encoders.fastbpe import fastBPE\n","# # Khởi tạo Byte Pair Encoding cho PhoBERT\n","# class BPE():\n","#   bpe_codes = 'PhoBERT_base_fairseq/bpe.codes'\n","# args = BPE()\n","# #----------Incorporate the BPE encoder into PhoBERT-----------#\n","# phoBERT.bpe = fastBPE(args) \n","# #-------------encode --------------#\n","# tokens = phoBERT.encode('Debug la vấn đề thường ngày của 1 coder!!')\n","# print('tokens list : ', tokens)\n","# #-----------Decode ngược lại thành câu từ chuỗi index token---------------#\n","# phoBERT.decode(tokens)  # 'Hello world!'\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DH7zem3wgujI"},"source":["# Case 2 : Load pretrainModel PhoBERT use transformer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":230,"referenced_widgets":["b80757289ac441a192d4ddb74dd5a050","9073e1c3c99d41dda10c1dfb5044b920","87e2ced98b984509bf56d405ea89e371","fb43dee2d8ca4bcb89af427f3e4aced8","bc276a8c7c8e4907a1729e8a0ef529b9","02763daebcf34dbf910ed8fce9c90bd2","2b763c4efe624f30badb78efd74dd9fc","9bf9023ca07640698d7b80c0dde6981b","598453649f214fc6bc84d33824fd29e7","1dc7bb6340d746bfa06eea7f08f8f590","167ce4278b0647c19f24346ce1f6a804","26fa14b6d2914b1c98dd8e88b3288b41","8988ec43f415476d8d30a39e6fbec6b8","c1a0e28caa04466b86477c30c73e380d","33e0e55f1639454b9f053479a347bf73","8313780860da438d921be2a3e0c8cb0c","bd15c33cba3a4c5b80ad7d72b0a83569","48ab4820bb99402a88216d99e2197774","cbfa7e1d420b49afab449cdf3f474edb","05f48704e71e4270b67a3c39a5b60d90","60a4c14d115d403e821fb185838c6a46","b82155807589494da0c6812d85bdb1f8","e29698db0b524ac48258dddb92dad1fc","91672bd7667b4253b4d4fc5bafaf4b54","fc89383e67ae457c9f36136394682019","23a7b19a06b646a48c35af80dfed09e3","39856d05c62046538dcdf6e0aa012e54","8ecbae8e162a433994eaefae85ed5054","d19f03a9fd6f490194b23921a730fd2e","0e17824f89cb4605b35114e3f9dbf598","19d85a09096a40c385368bd132f45032","19a5541e62564a3daf134ec1aa6819d1"]},"id":"-y-tt42zs8e_","executionInfo":{"status":"ok","timestamp":1607795216630,"user_tz":-420,"elapsed":85734,"user":{"displayName":"truc tran trung","photoUrl":"","userId":"16854322956484545035"}},"outputId":"4f3f171c-6373-4638-d2f8-55e4142d7082"},"source":["import torch\n","from transformers import AutoModel, AutoTokenizer\n","\n","phoBERT = AutoModel.from_pretrained(\"vinai/phobert-base\")\n","custokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n","# ------add token ('\\n') to enter lines --------#\n","custokenizer.add_tokens('\\n')\n","# INPUT TEXT MUST BE ALREADY WORD-SEGMENTED!\n","line = \"Debug là việc thường xuyên của delevoper.\"\n","\n","input_ids = torch.tensor([custokenizer.encode(line)])\n","with torch.no_grad():\n","    features = phoBERT(input_ids)  # Models outputs are now tuples\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b80757289ac441a192d4ddb74dd5a050","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=557.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"598453649f214fc6bc84d33824fd29e7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=542923308.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd15c33cba3a4c5b80ad7d72b0a83569","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=895321.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc89383e67ae457c9f36136394682019","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1135173.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QLK72X-1VpKT"},"source":["## **Step2 . Code DATALOADER**\n","\n","\n","*   Create dataset read file train, test :return tokenizers ( len =256)\n","*   Dataloader\n","\n"]},{"cell_type":"code","metadata":{"id":"e6CtuMKhcEPE"},"source":["#--------------Create Dataset----------------#\n","import os\n","import torch\n","from torch.utils.data.dataset import Dataset\n","from transformers.tokenization_utils import PreTrainedTokenizer\n","from filelock import FileLock\n","from transformers.utils import logging\n","from typing import Dict, List, Optional\n","import pickle\n","import random\n","import time\n","logger = logging.get_logger(__name__)\n","\n","class PoemDataset(Dataset):\n","    \"\"\"\n","    This will be superseded by a framework-agnostic approach\n","    soon.\n","    Parameters:\n","    ----------\n","    tokenizers : is pretrain tokenizer of PhoBERT\n","    file_path  : path to file train, test\n","    block_size : size of 1 block , optinal\n","    cache_dir  : just load 1 once and saved\n","\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        tokenizer: PreTrainedTokenizer,\n","        file_path: str,\n","        block_size: int,\n","        overwrite_cache=False,\n","        cache_dir: Optional[str] = None,\n","    ):\n","        assert os.path.isfile(file_path), f\"Input file path {file_path} not found\"\n","        block_size = block_size - tokenizer.num_special_tokens_to_add(pair=False)\n","\n","        directory, filename = os.path.split(file_path)\n","        cached_features_file = os.path.join(\n","            cache_dir if cache_dir is not None else directory,\n","            \"cached_lm_{}_{}_{}\".format(\n","                tokenizer.__class__.__name__,\n","                str(block_size),\n","                filename,\n","            ),\n","        )\n","\n","        # -----------Make sure only the first process in distributed training processes the dataset,----------------#\n","        # ---------------------------------------and the others will use the cache------------------------#\n","        lock_path = cached_features_file + \".lock\"\n","        with FileLock(lock_path):\n","\n","            if os.path.exists(cached_features_file) and not overwrite_cache:\n","                start = time.time()\n","                with open(cached_features_file, \"rb\") as handle:\n","                    self.examples = pickle.load(handle)\n","                logger.info(\n","                    f\"Loading features from cached file {cached_features_file} [took %.3f s]\", time.time() - start\n","                )\n","\n","            else:\n","                logger.info(f\"Creating features from dataset file at {directory}\")\n","\n","                self.examples = []\n","                with open(file_path, encoding=\"utf-8\") as f:\n","                    text = f.read()\n","                #-----convert text to tokenizers----------------------------#\n","                '''\n","                1. Convert word -> subword (tokenizer.tokenize(text))\n","                2. COnvert subword -> number (tokenizer.convert_tokens_to_ids)\n","                '''\n","                tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n","\n","                # ------------- Truncate in block of block_size-----------------#\n","                #-----------Beacuse add_token('\\n') -> inds = 64001------------#\n","                #--------If len(block_size)>256 so cut and add_special_tokens (<s>, </s>)---------------#\n","                i = 0\n","                while i < len(tokenized_text) - block_size + 1:\n","                    inds = tokenized_text[i : i + block_size]\n","                    for j in range(0, len(inds)):\n","                        if inds[j]==64001:\n","                            inds = inds[j+1:] #remove the first \\n\n","                            break\n","                    for j in range(len(inds)-1, 0, -1):\n","                        if inds[j]==64001:\n","                            inds = inds[:j-1] #remove \\n\n","                            break\n","                    i += len(inds)\n","                    self.examples.append(\n","                        tokenizer.build_inputs_with_special_tokens(inds)\n","                    )\n","                    \n","                # Note that we are losing the last truncated example here for the sake of simplicity (no padding)\n","                # If your dataset is small, first you should loook for a bigger one :-) and second you\n","                # can change this behavior by adding (model specific) padding.\n","\n","                start = time.time()\n","                with open(cached_features_file, \"wb\") as handle:\n","                    pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","                logger.info(\n","                    \"Saving features into cached file %s [took %.3f s]\", cached_features_file, time.time() - start\n","                )\n","\n","    def __len__(self):\n","        return len(self.examples)\n","\n","    def __getitem__(self, i) -> torch.Tensor:\n","        return torch.tensor(self.examples[i], dtype=torch.long)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bq5yTPljc-f6"},"source":["#-----------Load dataset-----------------------#\n","from transformers import LineByLineTextDataset, DataCollatorForLanguageModeling, LineByLineWithSOPTextDataset\n","\n","def load_dataset(train_path, test_path, custokenizer):\n","    train_dataset = PoemDataset(\n","          tokenizer=custokenizer,\n","          file_path=train_path,\n","          block_size= 256)\n","     \n","    test_dataset = PoemDataset(\n","          tokenizer=custokenizer,\n","          file_path=test_path,\n","          block_size=256)   \n","    \n","    data_collator = DataCollatorForLanguageModeling(\n","        tokenizer=custokenizer, mlm=False,\n","    )\n","    return train_dataset,test_dataset,data_collator\n","\n","train_dataset,test_dataset,data_collator = load_dataset(train_path,test_path,custokenizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nvIguCLStamj","executionInfo":{"elapsed":67238,"status":"ok","timestamp":1607600623146,"user":{"displayName":"truc tran trung","photoUrl":"","userId":"16854322956484545035"},"user_tz":-420},"outputId":"961b594c-459c-46ac-be39-bf23778876ed"},"source":["#-----------Test dataloader----------------#\n","print(len(test_dataset))\n","print(len(train_dataset))\n","#-------------Test decode to sentence ---------------#\n","print(custokenizer.decode(test_dataset[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["52\n","1746\n","<s> trẻ trung trời đất cho ta \n"," thời gian đòi lại thế là ước mong \n"," mùa xuân như gái không chồng \n"," có bao nhiêu vẫn là không có gì \n"," người ơi hoa bẻ mang đi \n"," để mình ta với xanh rì trời xanh \n"," \n"," ở đâu chỉ những mộng êm \n"," ở đâu chắc chắn xây lên mặn mà \n"," đó là bến đậu của ta \n"," đó là tiếng hát đó là tứ thơ \n"," đó là chỗ hết vẩn vơ \n"," để ta mãi mãi đáng chờ đợi nhau \n"," \n"," nơi đây bao chàng ra đi \n"," để cho ai đặt bến ni không chồng \n"," cuộc chiến tranh chẳng chờ mong \n"," biết bao trai tráng xung phong lên đường \n"," hy sinh tại chốn chiến trường \n"," để người con gái nhớ thương trọn đời \n"," bao ngày nước mắt tuôn rơi \n"," hóa thành bia đá giữa trời mùa thu \n"," trở thành câu hát lời </s>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CQSNIU0_0DX9"},"source":["# **Step 3. Initialize Trainer with TrainingArguments and GPT-2 model**"]},{"cell_type":"code","metadata":{"id":"lk2-7XVd0Ils"},"source":["from transformers import Trainer, TrainingArguments, GPT2Config, GPT2LMHeadModel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":115,"referenced_widgets":["28aa0d7e7a964bb0bd1b6ace410ef00d","e74161468185435a9338b218eb4aed72","c9e533ddcac747bfafc872c46a104b61","62d02ae7fa8349d4895b192bce2d6706","b214f352f8be47faa7e52df25ea39270","06a15da863d749c59927e00e4bc57c40","fbbb250469d2403eb78ea45ed5d62657","db4e831ac34341f9a417b3ce94fbc177","86a2c7e098fb40a58d83f97fc4fc39f2","db9467ece2ae427cb93793b353d5903f","52ff69fb0ec34c6bad0be29956351f0d","ad0667c9af34402f8733279ff4c73b9f","2f04c89f3a5d4a8ea42ac37a9b509e71","68e2fb4f69a648359362872fd61831c6","d424fc2bc4f14a3c843e620b39b10c8b","0379aa738c79419d9a6a25309a12c70d"]},"id":"ZNwt_SQ30Jyp","executionInfo":{"elapsed":81307,"status":"ok","timestamp":1607600637231,"user":{"displayName":"truc tran trung","photoUrl":"","userId":"16854322956484545035"},"user_tz":-420},"outputId":"a478365c-436f-4dcc-83a5-353bc4b1dea0"},"source":["\n","#--------------------------Load  pretrain model GPT-2--------------------#\n","model_gpt2 = GPT2LMHeadModel.from_pretrained('gpt2')\n","# vntq.save_pretrained('/content/drive/MyDrive/BERT/save_modelGPT2/')\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28aa0d7e7a964bb0bd1b6ace410ef00d","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"86a2c7e098fb40a58d83f97fc4fc39f2","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UxfsySfdXmOb","executionInfo":{"elapsed":81298,"status":"ok","timestamp":1607600637233,"user":{"displayName":"truc tran trung","photoUrl":"","userId":"16854322956484545035"},"user_tz":-420},"outputId":"6be2a7c0-943f-4c09-a7af-add8eb9ccc87"},"source":["model_gpt2.config"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPT2Config {\n","  \"_name_or_path\": \"gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"gradient_checkpointing\": false,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oiInjDMqRjFu","executionInfo":{"elapsed":81291,"status":"ok","timestamp":1607600637234,"user":{"displayName":"truc tran trung","photoUrl":"","userId":"16854322956484545035"},"user_tz":-420},"outputId":"ac5b0e20-477d-42db-880e-91fb8adf8ef3"},"source":["model_gpt2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(50257, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",")"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50AvTqtM0PhK","executionInfo":{"elapsed":81284,"status":"ok","timestamp":1607600637235,"user":{"displayName":"truc tran trung","photoUrl":"","userId":"16854322956484545035"},"user_tz":-420},"outputId":"8b3d2e0d-f8fa-4d7e-d57d-011ad58fdd96"},"source":["# Check linear layer final of gpt2\n","model_gpt2.lm_head"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Linear(in_features=768, out_features=50257, bias=False)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOV2WqNFWS1s","executionInfo":{"elapsed":81277,"status":"ok","timestamp":1607600637235,"user":{"displayName":"truc tran trung","photoUrl":"","userId":"16854322956484545035"},"user_tz":-420},"outputId":"0ae4ea2b-841b-4a06-f6a5-a9e0e4be2b7c"},"source":["# Check weights of linear layer final\n","model_gpt2.lm_head.weight"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453],\n","        [ 0.0403, -0.0486,  0.0462,  ...,  0.0861,  0.0025,  0.0432],\n","        [-0.1275,  0.0479,  0.1841,  ...,  0.0899, -0.1297, -0.0879],\n","        ...,\n","        [-0.0445, -0.0548,  0.0123,  ...,  0.1044,  0.0978, -0.0695],\n","        [ 0.1860,  0.0167,  0.0461,  ..., -0.0963,  0.0785, -0.0225],\n","        [ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207]],\n","       requires_grad=True)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hb9JY5heSBWE","executionInfo":{"elapsed":81816,"status":"ok","timestamp":1607600637779,"user":{"displayName":"truc tran trung","photoUrl":"","userId":"16854322956484545035"},"user_tz":-420},"outputId":"76d7ad18-3e01-4357-89f9-baec046f9479"},"source":["# Random weights => fine-turning model\n","rand_weight = torch.rand(model_gpt2.lm_head.weight.shape)\n","print(rand_weight)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[0.5111, 0.7020, 0.7175,  ..., 0.7280, 0.4061, 0.9498],\n","        [0.0895, 0.8086, 0.6039,  ..., 0.4003, 0.9907, 0.0363],\n","        [0.3005, 0.7193, 0.2726,  ..., 0.4621, 0.2552, 0.2104],\n","        ...,\n","        [0.4353, 0.6130, 0.0160,  ..., 0.6971, 0.4949, 0.5223],\n","        [0.2368, 0.6301, 0.1006,  ..., 0.7782, 0.7717, 0.5698],\n","        [0.1846, 0.6800, 0.6224,  ..., 0.4731, 0.2500, 0.9200]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_mRyLwFzSKMZ"},"source":["model_gpt2.lm_head.weight = torch.nn.parameter.Parameter(rand_weight)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"akO2WOM5SOeX","executionInfo":{"elapsed":81806,"status":"ok","timestamp":1607600637781,"user":{"displayName":"truc tran trung","photoUrl":"","userId":"16854322956484545035"},"user_tz":-420},"outputId":"bb110501-e184-4765-e045-fce126c64497"},"source":["model_gpt2.lm_head.weight"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[0.5111, 0.7020, 0.7175,  ..., 0.7280, 0.4061, 0.9498],\n","        [0.0895, 0.8086, 0.6039,  ..., 0.4003, 0.9907, 0.0363],\n","        [0.3005, 0.7193, 0.2726,  ..., 0.4621, 0.2552, 0.2104],\n","        ...,\n","        [0.4353, 0.6130, 0.0160,  ..., 0.6971, 0.4949, 0.5223],\n","        [0.2368, 0.6301, 0.1006,  ..., 0.7782, 0.7717, 0.5698],\n","        [0.1846, 0.6800, 0.6224,  ..., 0.4731, 0.2500, 0.9200]],\n","       requires_grad=True)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rpEHY-aFpEa4","executionInfo":{"elapsed":87362,"status":"ok","timestamp":1607600643345,"user":{"displayName":"truc tran trung","photoUrl":"","userId":"16854322956484545035"},"user_tz":-420},"outputId":"bba63650-d49c-4b24-8c0b-4035e55a5092"},"source":["'''\n","Because GPT2 has vocabulary_size 50257 and (wte): Embedding(50257, 768)\n","So  convert vocabulary_size= 64002, Embedding(64002, 768)\n","'''\n","task_gpt2 = {\"text-generation\": {\"do_sample\": True, \"max_length\": 256}} #edit output size\n","config_gpt2 = configuration = GPT2Config(vocab_size=64002, n_positions=258, n_ctx=258,\n","                           task_specific_params=task_gpt2,\n","                           eos_token_id = 2,\n","                           bos_token_id = 0,\n","                           pad_token_id = 1,\n","                           sep_token_id = 2,\n","                          #  eos_token_id=custokenizer.eos_token_id,\n","                          #  bos_token_id=custokenizer.bos_token_id, \n","                          #  pad_token_id=custokenizer.pad_token_id,\n","                          #  sep_token_id=custokenizer.sep_token_id\n","                           )\n","model_gpt2 = GPT2LMHeadModel(config_gpt2)\n","model_gpt2\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(64002, 768)\n","    (wpe): Embedding(258, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=64002, bias=False)\n",")"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"inLX5VtRSW0u","executionInfo":{"elapsed":87354,"status":"ok","timestamp":1607600643346,"user":{"displayName":"truc tran trung","photoUrl":"","userId":"16854322956484545035"},"user_tz":-420},"outputId":"f901ae69-a1c6-48b5-ecb6-2a7749fad243"},"source":["# Check model gp2 custormer\n","model_gpt2.config"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 258,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 258,\n","  \"pad_token_id\": 1,\n","  \"resid_pdrop\": 0.1,\n","  \"sep_token_id\": 2,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 256\n","    }\n","  },\n","  \"use_cache\": true,\n","  \"vocab_size\": 64002\n","}"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"l7ZBxXp8sqvB"},"source":["#save model_gpt2 (vocabulary_size =64002)\n","model_gpt2.save_pretrained('/content/drive/MyDrive/BERT/save_modelGPT2/')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kQvb-ySSSlcw"},"source":["## NEW **MODEL**"]},{"cell_type":"code","metadata":{"id":"gY3kfaYQSp1Z"},"source":["task = {\"text-generation\": {\"do_sample\": True, \"max_length\": 256}} #edit output size"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b5yF-3tiSvDQ"},"source":["configuration = GPT2Config(vocab_size=64002, n_positions=258, n_ctx=258,\n","                           task_specific_params=task,\n","                           eos_token_id = 2,\n","                           bos_token_id = 0,\n","                           pad_token_id = 1,\n","                           sep_token_id = 2,\n","                          #  eos_token_id=custokenizer.eos_token_id,\n","                          #  bos_token_id=custokenizer.bos_token_id, \n","                          #  pad_token_id=custokenizer.pad_token_id,\n","                          #  sep_token_id=custokenizer.sep_token_id\n","                           )\n","poem = GPT2LMHeadModel(configuration)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5aJ5z-6lT68W","executionInfo":{"elapsed":98528,"status":"ok","timestamp":1607600654558,"user":{"displayName":"truc tran trung","photoUrl":"","userId":"16854322956484545035"},"user_tz":-420},"outputId":"5c255e1d-193d-4fac-9b7b-adee06656fb8"},"source":["poem"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(64002, 768)\n","    (wpe): Embedding(258, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=64002, bias=False)\n",")"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mwsdu0UyULrC","executionInfo":{"elapsed":105561,"status":"ok","timestamp":1607600661601,"user":{"displayName":"truc tran trung","photoUrl":"","userId":"16854322956484545035"},"user_tz":-420},"outputId":"86df97bd-3b86-459d-bfc0-08c726149e2b"},"source":["# Load weights of model_gpt2 ( random weights)\n","load_model_gpt2 = GPT2LMHeadModel.from_pretrained('/content/drive/MyDrive/BERT/save_modelGPT2/')\n","poem.load_state_dict(load_model_gpt2.state_dict())"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"AFRxvKipURy1"},"source":["#-----------Print process training ------------#\n","from transformers.trainer_callback import TrainerCallback\n","from transformers import pipeline\n","class PrinterCallback(TrainerCallback):\n","    def on_epoch_end(self, args, state, control, model=None, **kwargs):\n","        if int(state.epoch)%10==0:\n","            pipe = pipeline('text-generation', model=model, tokenizer=custokenizer, device=0)\n","            with open(\"/content/drive/MyDrive/BERT/sample.txt\", \"a\") as f:\n","                f.write(pipe('<s> tìm về một thuở hạ xưa')[0]['generated_text'])\n","                f.write(\"\\n===========================================\\n\")\n","                f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vDfkd4WLVM80"},"source":["\n","training_args = TrainingArguments(\n","    output_dir=\"/content/drive/MyDrive/BERT/gpt2-poem\", #The output directory\n","    overwrite_output_dir=True, #overwrite the content of the output directory\n","    num_train_epochs=200, # number of training epochs\n","    per_device_train_batch_size=8, # batch size for training  \n","    per_device_eval_batch_size=16,  # batch size for evaluation\n","    save_steps=5000, # after # steps model is saved \n","    save_total_limit = 2, # delete other checkpoints\n","    warmup_steps=500,    # number of warmup steps for learning rate scheduler\n","    logging_dir='/content/drive/MyDrive/BERT/gpt2-poem/logs', # directory for storing logs\n","    logging_steps=500,\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uK2JejroXEXx"},"source":["## **Step 4. TRAIN MODEL**"]},{"cell_type":"markdown","metadata":{"id":"M1BT1CQO8sH6"},"source":[""]},{"cell_type":"code","metadata":{"id":"Rm1loYWtXKt_"},"source":["device = torch.device('cuda')\n","trainer = Trainer(\n","    model=poem, # GPT2\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n","    callbacks = [PrinterCallback],\n","\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"id":"Mwlg8svjab_u","outputId":"370a192f-8aa6-4cfe-9e21-8161dced733e"},"source":["# -------Train and save model-----------#\n","trainer.train()\n","trainer.save_model()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='212' max='43800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  212/43800 1:51:25 < 385:26:27, 0.03 it/s, Epoch 0.96/200]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"0070RwXYkyRU"},"source":["## **Step 4. TEST MODEL**"]},{"cell_type":"code","metadata":{"id":"7qCf1Eppa7t6"},"source":["#-------Load model saved-----------------#\n","from transformers import pipeline\n","poem = pipeline('text-generation', model=\"/content/drive/MyDrive/BERT/gpt2-poem\", tokenizer=custokenizer, config={'max_length':1024})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8jAoqX0Zk1t0"},"source":["#Test\n","a = poem('chiều')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NX9eKnitxrGb","executionInfo":{"status":"ok","timestamp":1607795596112,"user_tz":-420,"elapsed":1130,"user":{"displayName":"truc tran trung","photoUrl":"","userId":"16854322956484545035"}},"outputId":"68d33901-cc53-41f1-e167-202ebc7a1883"},"source":["x = a[0]['generated_text']\n","print(x)\n","# print(a[0]['generated_text'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["chiều thu em về phía mái đình \n"," dáng thon giữa dưới long lanh tháng giêng \n"," trao nhau quyện nhĩ lạnh áo hồng \n"," tóc dài tóc trắng phiêu diêu bông \n"," nhịp buồn sao cứ nhẹ nhàng \n"," chung tay anh vội vã à ơi à \n"," âm khờ một thủa nương nuôi \n"," tu nào cũng chẳng quản chi nào ngờ \n"," \n"," mấy mươi năm ấy bon chen \n"," em là anh đến bím tóc mưa nguồn \n"," nắng mưa gom gió nhăn gà \n"," trong nhà bên đập chùm đồng cân mần \n"," anh đi tìm lấy chồng gà \n"," làm cho nhẹ hắt buông mành thời gian \n"," \n"," chị bồng con nít nhà nghèo \n"," cái chua rách nát nhàu bến bờ ao \n"," còn e ấp ủ cho trầu \n"," cứ lời ru lại cơn mưa cuối trời \n"," sao em run mục đồng xanh \n"," chiếc ba lô rách với vài lá trầu \n"," không mưa gió giật mình vừa \n"," cho tuổi thơ tóc thả dần vơi dày \n"," \n"," dòng sông hóa bóng mây che \n"," đợi chờ đợi gió níu mây thưa \n"," gịp rượi rụng gió giông tàn \n"," tháng tư nhịp sóng giữa dòng mương cuối làng \n"," rộng nước chảy chưa kịp nương \n"," tìm đâu thấy có vui này dệt duyên \n"," thanh cao gặp lúc lấy chồng \n"," gieo thêm mỗi đứa đi tìm\n"],"name":"stdout"}]}]}