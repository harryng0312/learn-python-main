{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.animation as animation\n",
    "import time\n",
    "import struct\n",
    "import tensorflow as tf\n",
    "import random as rd\n",
    "\n",
    "from array import array\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# my project\n",
    "from module.conf import PROJECT_DIR\n",
    "\n",
    "# %matplotlib tk\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load data:\n",
    "- Train data: 60k 28x28 images\n",
    "- Test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_path = \"/data/sample/mnist\"\n",
    "training_images_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/train-images.idx3-ubyte\"])\n",
    "training_labels_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/train-labels.idx1-ubyte\"])\n",
    "test_images_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/t10k-images.idx3-ubyte\"])\n",
    "test_labels_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/t10k-labels.idx1-ubyte\"])\n",
    "\n",
    "def read_images_labels(images_filepath, labels_filepath) -> tuple:\n",
    "    labels = []\n",
    "    with open(labels_filepath, 'rb') as file:\n",
    "        magic, size = struct.unpack(\">II\", file.read(8))\n",
    "        if magic != 2049:\n",
    "            raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "        # labels = array(\"B\", file.read())\n",
    "        labels = array(\"B\", file.read())\n",
    "\n",
    "    with open(images_filepath, 'rb') as file:\n",
    "        magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "        if magic != 2051:\n",
    "            raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "        image_data = array(\"B\", file.read())       \n",
    "     \n",
    "    images = []\n",
    "    # for i in range(size):\n",
    "    #     images.append([0] * rows * cols)\n",
    "    for i in range(size):\n",
    "        img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "        img = img.reshape(28, 28)\n",
    "        # images[i][:] = img\n",
    "        images.append(img)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def load_data() -> tuple:\n",
    "    x_train, y_train = read_images_labels(training_images_filepath, training_labels_filepath)\n",
    "    x_test, y_test = read_images_labels(test_images_filepath, test_labels_filepath)\n",
    "    return (x_train, y_train),(x_test, y_test)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{type(X_train[0])}\")\n",
    "# mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)/255\n",
    "y_train = np.asarray(y_train)\n",
    "X_test  = np.asarray(X_test)/255\n",
    "y_test  = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model: tf.keras.models.Model = tf.keras.models.Sequential(layers=[\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28,)),\n",
    "    # tf.keras.layers.Dense(units=25, activation=tf.keras.activations.relu),\n",
    "    # tf.keras.layers.Dense(units=15, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(units=128, activation=tf.keras.activations.relu),\n",
    "    # tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=10, activation=tf.keras.activations.linear)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "# model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "#               loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "#               metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.FalseNegatives()])\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "              loss=loss_fn,\n",
    "              metrics=[\"accuracy\", \"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test = np.asarray(X_train) / 255.0, np.asarray(X_test) / 255.0\n",
    "print(X_train.shape)\n",
    "\n",
    "# model.fit(X_train, y_train, epochs=24, batch_size=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.2706 - accuracy: 0.9253 - mae: 5.7893 - 2s/epoch - 5ms/step\n",
      "can not predict:3136: 0.34409135580062866\n",
      "- [7]:img[3436]:[[1.67532289e-05 5.67955136e-01 1.51821613e-01 1.01415925e-02\n",
      "  2.97620404e-03 1.92857552e-02 5.20323217e-02 1.23961411e-01\n",
      "  6.20248057e-02 9.78442933e-03]]\n",
      "pred:0.5679551362991333\n",
      "predict:1 solve:2\n",
      "- [8]:img[1901]:[[3.4738739e-05 1.8349192e-04 4.5578633e-03 3.1608408e-03 8.2679886e-01\n",
      "  3.3020590e-02 6.9132992e-03 9.0115092e-04 6.8897292e-02 5.5531837e-02]]\n",
      "pred:0.8267988562583923\n",
      "predict:4 solve:9\n",
      "can not predict:1128: 0.3912167251110077\n",
      "- [18]:img[1981]:[[4.2353950e-05 3.7868874e-04 1.0734836e-02 2.1206947e-04 8.0766791e-01\n",
      "  4.4138628e-04 1.4424849e-01 3.7029688e-04 7.3830611e-03 2.8520858e-02]]\n",
      "pred:0.8076679110527039\n",
      "predict:4 solve:6\n",
      "can not predict:4640: 0.3267766237258911\n",
      "- [53]:img[4256]:[[1.5969522e-01 2.7626791e-07 5.2001953e-01 3.1909066e-01 4.2778967e-09\n",
      "  2.5060418e-04 8.4739580e-04 5.9816321e-05 3.3820888e-05 2.6491678e-06]]\n",
      "pred:0.52001953125\n",
      "predict:2 solve:3\n",
      "can not predict:241: 0.47260797023773193\n",
      "can not predict:6023: 0.4058820307254791\n",
      "error: 4 can not pred:5\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test,  y_test, verbose=2)\n",
    "c = 0\n",
    "cp = 0\n",
    "for i in range(100):\n",
    "    test_indx = rd.randint(0, len(y_test)-1)\n",
    "    x_test_ = np.asarray([X_test[test_indx]])\n",
    "\n",
    "    # test_indx = rd.randint(0, len(y_train)-1)\n",
    "    # x_test_ = np.asarray([X_train[test_indx]])\n",
    "\n",
    "    result = model.predict(x=x_test_, verbose=0)\n",
    "    result = tf.nn.softmax(result).numpy()\n",
    "    y_test_ = y_test\n",
    "    if result.max() >= 0.5:\n",
    "        if result.argmax() != y_test_[test_indx]:\n",
    "            c+=1\n",
    "            print(f\"- [{i}]:img[{test_indx}]:{result}\\npred:{result.max()}\\npredict:{result.argmax()} solve:{y_test_[test_indx]}\")\n",
    "    else:\n",
    "        print(f\"can not predict:{test_indx}: {result.max()}\")\n",
    "        cp+=1\n",
    "print(f\"error: {c} can not pred:{cp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 160x120 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_image(img_data: np.ndarray) -> tuple:\n",
    "    fig, axes = plt.subplots(figsize=(1.60, 1.20))\n",
    "    axes.imshow(X=img_data, cmap=\"gray\")\n",
    "    return fig, axes\n",
    "\n",
    "# print(y_test[5854])\n",
    "show_image(X_test[1901])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
    "# tf.config.experimental_connect_to_cluster(resolver)\n",
    "# # This is the TPU initialization code that has to be at the beginning.\n",
    "# tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "# print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
