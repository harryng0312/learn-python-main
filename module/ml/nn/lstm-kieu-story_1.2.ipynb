{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.callbacks import LambdaCallback\nfrom tensorflow.keras.models import Model, load_model, Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout, Input, Masking\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.utils import get_file, to_categorical\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nimport tensorflow as tf\nimport numpy as np\nimport random\nimport sys\nimport io","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-02T17:54:58.813651Z","iopub.execute_input":"2023-11-02T17:54:58.814027Z","iopub.status.idle":"2023-11-02T17:54:58.820284Z","shell.execute_reply.started":"2023-11-02T17:54:58.813995Z","shell.execute_reply":"2023-11-02T17:54:58.819362Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"strategy  = tf.distribute.get_strategy()\nwith strategy.scope():\n    print(f\"{tf.config.list_physical_devices('GPU') }\")","metadata":{"execution":{"iopub.status.busy":"2023-11-02T17:54:58.823973Z","iopub.execute_input":"2023-11-02T17:54:58.824257Z","iopub.status.idle":"2023-11-02T17:54:58.834834Z","shell.execute_reply.started":"2023-11-02T17:54:58.824234Z","shell.execute_reply":"2023-11-02T17:54:58.833973Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","output_type":"stream"}]},{"cell_type":"code","source":"data_file_path = '/kaggle/input/kieu-story-txt/truyen_kieu_data_pre.txt'\n\ndef load_data() -> tuple:\n    rs: map = {}\n    ls = []\n    tmp_line = \"\"\n    with open(file=data_file_path, mode=\"rt\") as i_f:\n        count = 0\n        for line in i_f:\n            line = line.strip()\n            if \"\" == line: continue\n            if count % 2 == 0 and tmp_line!=\"\":\n                ls.append(tmp_line.strip())\n                tmp_line = \"\"\n                pass\n#             tmp_line += (\" | \" if tmp_line!=\"\" else \"\") + line\n            tmp_line += \" \"+line\n            a_word = line.split()\n            for word in a_word:\n                if word not in rs:\n                    rs[word] = 0\n                    pass\n                rs[word]+=1\n                pass\n            pass\n            count+=1\n        pass\n    return rs, ls","metadata":{"execution":{"iopub.status.busy":"2023-11-02T17:54:58.836409Z","iopub.execute_input":"2023-11-02T17:54:58.837048Z","iopub.status.idle":"2023-11-02T17:54:58.846865Z","shell.execute_reply.started":"2023-11-02T17:54:58.837015Z","shell.execute_reply":"2023-11-02T17:54:58.846120Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"bag_of_words, coupled_lines = load_data()\n# bag_of_words[\"|\"] = len(coupled_lines)\n# bag_of_words[\"\\\\\"] = len(coupled_lines) - 1\n# ix_to_word = [*bag_of_words.keys()]\nkeys = [*bag_of_words.keys()]\nword_to_ix = { w:i for i,w in enumerate(keys) }\nix_to_word = { i:w for i,w in enumerate(keys) }\n# coupled_lines\n# values = [*bag_of_word.values()]\n# sum(values)\n# len(bag_of_words)\n# ix_to_word\nX_train = [[word_to_ix[word] for word in coupled_line.split()] for coupled_line in coupled_lines]\n\ndelta_line = 1\n# y_train = [line[5] for line in X_train[delta_line:]]\ny_train = [*X_train[delta_line:]]\ny_train = [e[0] for e in y_train]\nfor c in range(delta_line):\n    y_train.append(X_train[c][0])\n    pass\n\ntotal_word = len(bag_of_words)\nmax_input_len = 14\nX_train = np.asarray(a=X_train, dtype=int)\ny_train = np.asarray(y_train) #.reshape(X_train.shape[0], 1)\n# print(y_train.shape)\ny_train = to_categorical(y_train, num_classes=total_word, dtype=int)\n# X_train.shape\n# y_train.shape\n# len(coupled_lines[0].split())\n# coupled_lines","metadata":{"execution":{"iopub.status.busy":"2023-11-02T17:54:58.848328Z","iopub.execute_input":"2023-11-02T17:54:58.848591Z","iopub.status.idle":"2023-11-02T17:54:58.890762Z","shell.execute_reply.started":"2023-11-02T17:54:58.848569Z","shell.execute_reply":"2023-11-02T17:54:58.890034Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"model: tf.keras.Model = tf.keras.Sequential(name=\"LSTM-RNN\")\n# input = tf.keras.layers.Input(shape=(15))\nembedding_1 = tf.keras.layers.Embedding(input_dim=total_word, output_dim=2048, input_length=max_input_len)\nbidrect_1 = tf.keras.layers.Bidirectional(\\\n    layer=tf.keras.layers.LSTM(units=14*32, return_sequences=True, go_backwards=False),\\\n    backward_layer=tf.keras.layers.LSTM(units=14*24, return_sequences=True, go_backwards=True))\ndropout = tf.keras.layers.Dropout(rate=0.4)\nbidrect_2 = tf.keras.layers.Bidirectional(layer=tf.keras.layers.LSTM(units=14*16, return_sequences=True))\ndropout = tf.keras.layers.Dropout(rate=0.6)\nlstm = tf.keras.layers.LSTM(units=14*16)\noutput_1 = tf.keras.layers.Dense(units=total_word, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(1e-2))\noutput_2 = tf.keras.layers.Dense(units=total_word, activation=\"softmax\")\n\n# model.add(input)\nmodel.add(embedding_1)\nmodel.add(bidrect_1)\nmodel.add(bidrect_2)\nmodel.add(dropout)\nmodel.add(lstm)\nmodel.add(output_1)\nmodel.add(output_2)\n\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T18:04:30.197398Z","iopub.execute_input":"2023-11-02T18:04:30.197767Z","iopub.status.idle":"2023-11-02T18:04:31.681802Z","shell.execute_reply.started":"2023-11-02T18:04:30.197737Z","shell.execute_reply":"2023-11-02T18:04:31.680910Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Model: \"LSTM-RNN\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding_9 (Embedding)     (None, 14, 2048)          4900864   \n                                                                 \n bidirectional_13 (Bidirecti  (None, 14, 784)          7680064   \n onal)                                                           \n                                                                 \n bidirectional_14 (Bidirecti  (None, 14, 448)          1808128   \n onal)                                                           \n                                                                 \n dropout_14 (Dropout)        (None, 14, 448)           0         \n                                                                 \n lstm_34 (LSTM)              (None, 224)               603008    \n                                                                 \n dense_18 (Dense)            (None, 2393)              538425    \n                                                                 \n dense_19 (Dense)            (None, 2393)              5728842   \n                                                                 \n=================================================================\nTotal params: 21,259,331\nTrainable params: 21,259,331\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"tf.config.set_soft_device_placement(True) \n# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n# loss_fn = tf.keras.losses.sparse_categorical_crossentropy\nloss_fn = tf.keras.losses.categorical_crossentropy\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n              loss=loss_fn,\n              metrics=[\"accuracy\"])\n# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n#               loss=loss_fn,\n#               metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-11-02T18:04:35.596198Z","iopub.execute_input":"2023-11-02T18:04:35.596926Z","iopub.status.idle":"2023-11-02T18:04:35.611584Z","shell.execute_reply.started":"2023-11-02T18:04:35.596893Z","shell.execute_reply":"2023-11-02T18:04:35.610541Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# strategy  = tf.distribute.get_strategy()\nwith strategy.scope():\n    model.reset_metrics()\n    model.reset_states()\n# with tf.device('/cpu:0'):\n# with tf.device(\"/gpu:0\"):\n    model.fit(x=X_train, y=y_train, epochs=160, batch_size=128, verbose=1)\n#     model.fit(x=X_train, y=y_train, epochs=75, batch_size=64, verbose=1)\n    pass","metadata":{"execution":{"iopub.status.busy":"2023-11-02T18:04:39.498168Z","iopub.execute_input":"2023-11-02T18:04:39.498985Z","iopub.status.idle":"2023-11-02T18:06:19.418415Z","shell.execute_reply.started":"2023-11-02T18:04:39.498950Z","shell.execute_reply":"2023-11-02T18:06:19.417399Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Epoch 1/160\n13/13 [==============================] - 11s 171ms/step - loss: 10.3098 - accuracy: 0.0270\nEpoch 2/160\n13/13 [==============================] - 2s 113ms/step - loss: 7.6492 - accuracy: 0.0246\nEpoch 3/160\n13/13 [==============================] - 2s 135ms/step - loss: 6.7370 - accuracy: 0.0344\nEpoch 4/160\n13/13 [==============================] - 2s 124ms/step - loss: 6.3666 - accuracy: 0.0246\nEpoch 5/160\n13/13 [==============================] - 1s 78ms/step - loss: 6.1828 - accuracy: 0.0344\nEpoch 6/160\n13/13 [==============================] - 1s 89ms/step - loss: 6.0878 - accuracy: 0.0344\nEpoch 7/160\n13/13 [==============================] - 1s 68ms/step - loss: 6.0410 - accuracy: 0.0344\nEpoch 8/160\n13/13 [==============================] - 1s 89ms/step - loss: 6.0177 - accuracy: 0.0344\nEpoch 9/160\n13/13 [==============================] - 1s 77ms/step - loss: 6.0066 - accuracy: 0.0344\nEpoch 10/160\n13/13 [==============================] - 1s 67ms/step - loss: 5.9938 - accuracy: 0.0350\nEpoch 11/160\n13/13 [==============================] - 1s 58ms/step - loss: 5.9520 - accuracy: 0.0344\nEpoch 12/160\n13/13 [==============================] - 1s 68ms/step - loss: 5.9238 - accuracy: 0.0344\nEpoch 13/160\n13/13 [==============================] - 1s 67ms/step - loss: 5.9027 - accuracy: 0.0283\nEpoch 14/160\n13/13 [==============================] - 1s 56ms/step - loss: 5.8587 - accuracy: 0.0344\nEpoch 15/160\n13/13 [==============================] - 1s 44ms/step - loss: 5.8240 - accuracy: 0.0332\nEpoch 16/160\n13/13 [==============================] - 1s 68ms/step - loss: 5.7705 - accuracy: 0.0344\nEpoch 17/160\n13/13 [==============================] - 1s 58ms/step - loss: 5.7169 - accuracy: 0.0270\nEpoch 18/160\n13/13 [==============================] - 1s 67ms/step - loss: 5.6222 - accuracy: 0.0338\nEpoch 19/160\n13/13 [==============================] - 1s 57ms/step - loss: 5.5106 - accuracy: 0.0375\nEpoch 20/160\n13/13 [==============================] - 1s 55ms/step - loss: 5.4539 - accuracy: 0.0356\nEpoch 21/160\n13/13 [==============================] - 1s 55ms/step - loss: 5.3813 - accuracy: 0.0246\nEpoch 22/160\n13/13 [==============================] - 1s 44ms/step - loss: 5.2930 - accuracy: 0.0344\nEpoch 23/160\n13/13 [==============================] - 1s 44ms/step - loss: 5.2162 - accuracy: 0.0381\nEpoch 24/160\n13/13 [==============================] - 1s 55ms/step - loss: 5.1153 - accuracy: 0.0412\nEpoch 25/160\n13/13 [==============================] - 1s 44ms/step - loss: 5.0665 - accuracy: 0.0418\nEpoch 26/160\n13/13 [==============================] - 1s 44ms/step - loss: 4.9567 - accuracy: 0.0369\nEpoch 27/160\n13/13 [==============================] - 1s 44ms/step - loss: 4.8749 - accuracy: 0.0479\nEpoch 28/160\n13/13 [==============================] - 0s 32ms/step - loss: 4.8204 - accuracy: 0.0381\nEpoch 29/160\n13/13 [==============================] - 1s 44ms/step - loss: 4.7267 - accuracy: 0.0608\nEpoch 30/160\n13/13 [==============================] - 1s 55ms/step - loss: 4.6908 - accuracy: 0.0559\nEpoch 31/160\n13/13 [==============================] - 0s 32ms/step - loss: 4.6563 - accuracy: 0.0584\nEpoch 32/160\n13/13 [==============================] - 1s 44ms/step - loss: 4.5810 - accuracy: 0.0602\nEpoch 33/160\n13/13 [==============================] - 1s 44ms/step - loss: 4.5217 - accuracy: 0.0694\nEpoch 34/160\n13/13 [==============================] - 1s 44ms/step - loss: 4.4421 - accuracy: 0.0627\nEpoch 35/160\n13/13 [==============================] - 1s 44ms/step - loss: 4.3743 - accuracy: 0.0756\nEpoch 36/160\n13/13 [==============================] - 1s 46ms/step - loss: 4.2869 - accuracy: 0.0762\nEpoch 37/160\n13/13 [==============================] - 1s 44ms/step - loss: 4.2137 - accuracy: 0.0854\nEpoch 38/160\n13/13 [==============================] - 1s 67ms/step - loss: 4.1516 - accuracy: 0.0885\nEpoch 39/160\n13/13 [==============================] - 0s 33ms/step - loss: 4.0874 - accuracy: 0.0952\nEpoch 40/160\n13/13 [==============================] - 1s 32ms/step - loss: 4.0565 - accuracy: 0.1014\nEpoch 41/160\n13/13 [==============================] - 0s 33ms/step - loss: 4.1061 - accuracy: 0.1007\nEpoch 42/160\n13/13 [==============================] - 1s 56ms/step - loss: 4.0642 - accuracy: 0.1007\nEpoch 43/160\n13/13 [==============================] - 0s 32ms/step - loss: 4.1374 - accuracy: 0.1020\nEpoch 44/160\n13/13 [==============================] - 1s 44ms/step - loss: 4.0391 - accuracy: 0.1106\nEpoch 45/160\n13/13 [==============================] - 0s 32ms/step - loss: 3.9521 - accuracy: 0.1161\nEpoch 46/160\n13/13 [==============================] - 0s 32ms/step - loss: 3.8303 - accuracy: 0.1278\nEpoch 47/160\n13/13 [==============================] - 1s 44ms/step - loss: 3.7570 - accuracy: 0.1204\nEpoch 48/160\n13/13 [==============================] - 1s 44ms/step - loss: 3.7363 - accuracy: 0.1437\nEpoch 49/160\n13/13 [==============================] - 0s 32ms/step - loss: 3.6646 - accuracy: 0.1425\nEpoch 50/160\n13/13 [==============================] - 1s 44ms/step - loss: 3.5961 - accuracy: 0.1511\nEpoch 51/160\n13/13 [==============================] - 1s 44ms/step - loss: 3.6064 - accuracy: 0.1468\nEpoch 52/160\n13/13 [==============================] - 1s 44ms/step - loss: 3.5432 - accuracy: 0.1597\nEpoch 53/160\n13/13 [==============================] - 0s 33ms/step - loss: 3.4464 - accuracy: 0.1708\nEpoch 54/160\n13/13 [==============================] - 0s 33ms/step - loss: 3.3734 - accuracy: 0.1818\nEpoch 55/160\n13/13 [==============================] - 1s 46ms/step - loss: 3.3301 - accuracy: 0.1953\nEpoch 56/160\n13/13 [==============================] - 1s 44ms/step - loss: 3.3373 - accuracy: 0.1898\nEpoch 57/160\n13/13 [==============================] - 1s 44ms/step - loss: 3.3706 - accuracy: 0.1861\nEpoch 58/160\n13/13 [==============================] - 0s 33ms/step - loss: 3.3598 - accuracy: 0.1972\nEpoch 59/160\n13/13 [==============================] - 1s 45ms/step - loss: 3.2624 - accuracy: 0.2138\nEpoch 60/160\n13/13 [==============================] - 0s 32ms/step - loss: 3.1489 - accuracy: 0.2383\nEpoch 61/160\n13/13 [==============================] - 0s 32ms/step - loss: 3.1426 - accuracy: 0.2303\nEpoch 62/160\n13/13 [==============================] - 1s 57ms/step - loss: 3.0884 - accuracy: 0.2432\nEpoch 63/160\n13/13 [==============================] - 1s 44ms/step - loss: 3.0241 - accuracy: 0.2549\nEpoch 64/160\n13/13 [==============================] - 1s 44ms/step - loss: 2.9793 - accuracy: 0.2758\nEpoch 65/160\n13/13 [==============================] - 1s 44ms/step - loss: 2.9154 - accuracy: 0.2789\nEpoch 66/160\n13/13 [==============================] - 1s 44ms/step - loss: 2.8787 - accuracy: 0.2807\nEpoch 67/160\n13/13 [==============================] - 0s 32ms/step - loss: 2.8041 - accuracy: 0.3188\nEpoch 68/160\n13/13 [==============================] - 0s 32ms/step - loss: 2.7523 - accuracy: 0.3292\nEpoch 69/160\n13/13 [==============================] - 0s 32ms/step - loss: 2.6875 - accuracy: 0.3372\nEpoch 70/160\n13/13 [==============================] - 1s 66ms/step - loss: 2.6261 - accuracy: 0.3704\nEpoch 71/160\n13/13 [==============================] - 1s 44ms/step - loss: 2.5810 - accuracy: 0.3729\nEpoch 72/160\n13/13 [==============================] - 0s 33ms/step - loss: 2.5504 - accuracy: 0.3919\nEpoch 73/160\n13/13 [==============================] - 1s 60ms/step - loss: 2.5332 - accuracy: 0.3913\nEpoch 74/160\n13/13 [==============================] - 1s 44ms/step - loss: 2.5396 - accuracy: 0.3986\nEpoch 75/160\n13/13 [==============================] - 0s 33ms/step - loss: 2.4780 - accuracy: 0.4171\nEpoch 76/160\n13/13 [==============================] - 0s 33ms/step - loss: 2.4297 - accuracy: 0.4404\nEpoch 77/160\n13/13 [==============================] - 0s 32ms/step - loss: 2.4174 - accuracy: 0.4189\nEpoch 78/160\n13/13 [==============================] - 0s 33ms/step - loss: 2.4093 - accuracy: 0.4429\nEpoch 79/160\n13/13 [==============================] - 0s 33ms/step - loss: 2.3666 - accuracy: 0.4619\nEpoch 80/160\n13/13 [==============================] - 0s 32ms/step - loss: 2.4937 - accuracy: 0.4152\nEpoch 81/160\n13/13 [==============================] - 0s 33ms/step - loss: 2.5273 - accuracy: 0.4072\nEpoch 82/160\n13/13 [==============================] - 0s 33ms/step - loss: 2.4973 - accuracy: 0.4214\nEpoch 83/160\n13/13 [==============================] - 1s 45ms/step - loss: 2.4817 - accuracy: 0.4115\nEpoch 84/160\n13/13 [==============================] - 0s 33ms/step - loss: 2.3781 - accuracy: 0.4269\nEpoch 85/160\n13/13 [==============================] - 1s 44ms/step - loss: 2.2699 - accuracy: 0.4668\nEpoch 86/160\n13/13 [==============================] - 0s 33ms/step - loss: 2.2353 - accuracy: 0.4840\nEpoch 87/160\n13/13 [==============================] - 0s 33ms/step - loss: 2.5177 - accuracy: 0.4281\nEpoch 88/160\n13/13 [==============================] - 0s 33ms/step - loss: 2.5630 - accuracy: 0.4263\nEpoch 89/160\n13/13 [==============================] - 0s 33ms/step - loss: 2.4460 - accuracy: 0.4625\nEpoch 90/160\n13/13 [==============================] - 1s 44ms/step - loss: 2.2846 - accuracy: 0.4982\nEpoch 91/160\n13/13 [==============================] - 1s 56ms/step - loss: 2.1297 - accuracy: 0.5197\nEpoch 92/160\n13/13 [==============================] - 0s 33ms/step - loss: 2.0551 - accuracy: 0.5534\nEpoch 93/160\n13/13 [==============================] - 1s 44ms/step - loss: 1.9718 - accuracy: 0.5737\nEpoch 94/160\n13/13 [==============================] - 1s 46ms/step - loss: 1.9357 - accuracy: 0.5921\nEpoch 95/160\n13/13 [==============================] - 1s 44ms/step - loss: 1.8766 - accuracy: 0.6014\nEpoch 96/160\n13/13 [==============================] - 1s 55ms/step - loss: 1.7954 - accuracy: 0.6376\nEpoch 97/160\n13/13 [==============================] - 1s 44ms/step - loss: 1.7557 - accuracy: 0.6572\nEpoch 98/160\n13/13 [==============================] - 0s 32ms/step - loss: 1.7289 - accuracy: 0.6529\nEpoch 99/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.6971 - accuracy: 0.6658\nEpoch 100/160\n13/13 [==============================] - 1s 45ms/step - loss: 1.6412 - accuracy: 0.6880\nEpoch 101/160\n13/13 [==============================] - 1s 44ms/step - loss: 1.5807 - accuracy: 0.7058\nEpoch 102/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.5335 - accuracy: 0.7254\nEpoch 103/160\n13/13 [==============================] - 0s 32ms/step - loss: 1.5195 - accuracy: 0.7377\nEpoch 104/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.4565 - accuracy: 0.7482\nEpoch 105/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.4214 - accuracy: 0.7795\nEpoch 106/160\n13/13 [==============================] - 1s 56ms/step - loss: 1.4051 - accuracy: 0.7660\nEpoch 107/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.3579 - accuracy: 0.7783\nEpoch 108/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.3469 - accuracy: 0.7844\nEpoch 109/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.2870 - accuracy: 0.7942\nEpoch 110/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.2731 - accuracy: 0.8077\nEpoch 111/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.2254 - accuracy: 0.8280\nEpoch 112/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.2222 - accuracy: 0.8114\nEpoch 113/160\n13/13 [==============================] - 1s 45ms/step - loss: 1.2321 - accuracy: 0.8206\nEpoch 114/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.2126 - accuracy: 0.8237\nEpoch 115/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.1654 - accuracy: 0.8299\nEpoch 116/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.1453 - accuracy: 0.8434\nEpoch 117/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.1238 - accuracy: 0.8477\nEpoch 118/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.1176 - accuracy: 0.8593\nEpoch 119/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.0890 - accuracy: 0.8606\nEpoch 120/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.0831 - accuracy: 0.8520\nEpoch 121/160\n13/13 [==============================] - 1s 45ms/step - loss: 1.0637 - accuracy: 0.8618\nEpoch 122/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.0130 - accuracy: 0.8778\nEpoch 123/160\n13/13 [==============================] - 1s 46ms/step - loss: 0.9903 - accuracy: 0.8833\nEpoch 124/160\n13/13 [==============================] - 0s 33ms/step - loss: 0.9600 - accuracy: 0.8913\nEpoch 125/160\n13/13 [==============================] - 0s 33ms/step - loss: 0.9589 - accuracy: 0.8845\nEpoch 126/160\n13/13 [==============================] - 1s 45ms/step - loss: 0.9594 - accuracy: 0.8900\nEpoch 127/160\n13/13 [==============================] - 0s 33ms/step - loss: 0.9406 - accuracy: 0.8900\nEpoch 128/160\n13/13 [==============================] - 0s 33ms/step - loss: 0.9535 - accuracy: 0.8980\nEpoch 129/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.0990 - accuracy: 0.8446\nEpoch 130/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.1157 - accuracy: 0.8458\nEpoch 131/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.2482 - accuracy: 0.8041\nEpoch 132/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.2303 - accuracy: 0.8041\nEpoch 133/160\n13/13 [==============================] - 1s 44ms/step - loss: 1.1957 - accuracy: 0.7930\nEpoch 134/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.1760 - accuracy: 0.8139\nEpoch 135/160\n13/13 [==============================] - 0s 33ms/step - loss: 1.1219 - accuracy: 0.8434\nEpoch 136/160\n13/13 [==============================] - 1s 48ms/step - loss: 1.0686 - accuracy: 0.8489\nEpoch 137/160\n13/13 [==============================] - 0s 35ms/step - loss: 0.9895 - accuracy: 0.8686\nEpoch 138/160\n13/13 [==============================] - 0s 33ms/step - loss: 0.9103 - accuracy: 0.8907\nEpoch 139/160\n13/13 [==============================] - 1s 45ms/step - loss: 0.8778 - accuracy: 0.9128\nEpoch 140/160\n13/13 [==============================] - 1s 44ms/step - loss: 0.8524 - accuracy: 0.9091\nEpoch 141/160\n13/13 [==============================] - 0s 33ms/step - loss: 0.7925 - accuracy: 0.9281\nEpoch 142/160\n13/13 [==============================] - 0s 33ms/step - loss: 0.7567 - accuracy: 0.9300\nEpoch 143/160\n13/13 [==============================] - 1s 45ms/step - loss: 0.7219 - accuracy: 0.9496\nEpoch 144/160\n13/13 [==============================] - 0s 33ms/step - loss: 0.6954 - accuracy: 0.9478\nEpoch 145/160\n13/13 [==============================] - 0s 33ms/step - loss: 0.6774 - accuracy: 0.9552\nEpoch 146/160\n13/13 [==============================] - 1s 44ms/step - loss: 0.6594 - accuracy: 0.9644\nEpoch 147/160\n13/13 [==============================] - 0s 33ms/step - loss: 0.6370 - accuracy: 0.9638\nEpoch 148/160\n13/13 [==============================] - 0s 33ms/step - loss: 0.6319 - accuracy: 0.9595\nEpoch 149/160\n13/13 [==============================] - 0s 33ms/step - loss: 0.6109 - accuracy: 0.9644\nEpoch 150/160\n13/13 [==============================] - 0s 33ms/step - loss: 0.5971 - accuracy: 0.9717\nEpoch 151/160\n13/13 [==============================] - 0s 33ms/step - loss: 0.5793 - accuracy: 0.9699\nEpoch 152/160\n13/13 [==============================] - 0s 32ms/step - loss: 0.5688 - accuracy: 0.9724\nEpoch 153/160\n13/13 [==============================] - 0s 32ms/step - loss: 0.5557 - accuracy: 0.9810\nEpoch 154/160\n13/13 [==============================] - 0s 32ms/step - loss: 0.5458 - accuracy: 0.9791\nEpoch 155/160\n13/13 [==============================] - 0s 32ms/step - loss: 0.5420 - accuracy: 0.9760\nEpoch 156/160\n13/13 [==============================] - 0s 33ms/step - loss: 0.5288 - accuracy: 0.9810\nEpoch 157/160\n13/13 [==============================] - 1s 44ms/step - loss: 0.5206 - accuracy: 0.9797\nEpoch 158/160\n13/13 [==============================] - 0s 33ms/step - loss: 0.5065 - accuracy: 0.9803\nEpoch 159/160\n13/13 [==============================] - 0s 32ms/step - loss: 0.4949 - accuracy: 0.9859\nEpoch 160/160\n13/13 [==============================] - 0s 32ms/step - loss: 0.4916 - accuracy: 0.9853\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('/kaggle/working/kieu_story')","metadata":{"execution":{"iopub.status.busy":"2023-11-02T17:56:14.388425Z","iopub.execute_input":"2023-11-02T17:56:14.388773Z","iopub.status.idle":"2023-11-02T17:56:24.446894Z","shell.execute_reply.started":"2023-11-02T17:56:14.388740Z","shell.execute_reply":"2023-11-02T17:56:24.445686Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"Exception ignored in: <function _xla_gc_callback at 0x7eaa0a772320>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/jax/_src/lib/__init__.py\", line 103, in _xla_gc_callback\n    def _xla_gc_callback(*args):\nKeyboardInterrupt: \n\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport subprocess\nfrom IPython.display import FileLink, display\ndownload_file_name = 'kieu_story'\npath = f\"/kaggle/working/{download_file_name}\"\nzip_name = f\"/kaggle/working/{download_file_name}.zip\"\ncommand = f\"zip {zip_name} {path} -r\"\nresult = subprocess.run(command, shell=True, capture_output=True, text=True)\nif result.returncode != 0:\n    print(\"Unable to run zip command!\")\n    print(result.stderr)\ndisplay(FileLink(f'{download_file_name}.zip'))\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T17:56:24.447968Z","iopub.status.idle":"2023-11-02T17:56:24.448350Z","shell.execute_reply.started":"2023-11-02T17:56:24.448177Z","shell.execute_reply":"2023-11-02T17:56:24.448195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random as rd\n\nnum_of_word = max_input_len * 4\n# seed = \"đàn bà dễ có mấy tay đời xưa mấy mặt đời này mấy gan\"\nseed_arr = [ix_to_word[rd.randint(0, total_word)] for _ in range(14)]\nseed_arr[11] = seed_arr[5]\nseed = \" \".join(seed_arr).strip()\nseed_sequence = [word_to_ix[word] for word in seed.split()]\nrs = \"\"\nfor i in range(num_of_word):\n    if i % max_input_len == 0 and i != 0:\n#         seed_sequence.append(\" \\\\\")\n        rs += (\"\\n\")\n#         continue\n    if i % max_input_len == 6:\n#         seed_sequence.append(\" | \")\n        rs += (\"\\n\")\n#         continue\n    prediction = model.predict(np.array([seed_sequence]), verbose=\"0\")\n    predicted_word_idx = np.argmax(prediction)\n    predicted_word = ix_to_word[predicted_word_idx]\n    \n    seed_sequence.append(predicted_word_idx)\n    \n    if len(seed_sequence) % 6 == 0:\n        seed_sequence = seed_sequence[6:]\n    seed += \" \" + predicted_word\n    rs += \" \" + predicted_word\n\nprint(rs)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T18:06:46.694510Z","iopub.execute_input":"2023-11-02T18:06:46.694886Z","iopub.status.idle":"2023-11-02T18:06:52.910791Z","shell.execute_reply.started":"2023-11-02T18:06:46.694855Z","shell.execute_reply":"2023-11-02T18:06:52.909809Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":" sinh thân đã cười nước dắt\n những này trong quyết một nhớ khen điều\n một xót dưới bóng vội hỏi\n phải đạo nhân khóc rằng cùng phải chén\n sầu nhớ dễ đường phòng nhặt\n giác thôi giác thôi giác thôi chàng chàng\n chàng chàng chàng chàng này tiếc\n lỡ lại nhớ dẫu thôi khi ví khi\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}